<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ML Engineering on CS 210 Build Guide</title><link>http://localhost:1313/docs/ml/</link><description>Recent content in ML Engineering on CS 210 Build Guide</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 08 Jan 2025 10:55:07 -0800</lastBuildDate><atom:link href="http://localhost:1313/docs/ml/index.xml" rel="self" type="application/rss+xml"/><item><title>Basic ML</title><link>http://localhost:1313/docs/ml/basic/</link><pubDate>Wed, 08 Jan 2025 10:55:07 -0800</pubDate><guid>http://localhost:1313/docs/ml/basic/</guid><description>&lt;h1 id="basic-ml">
 Basic ML
 &lt;a class="anchor" href="#basic-ml">#&lt;/a>
&lt;/h1>
&lt;p>Below are some snippets for common ML use cases such as NLP &amp;ndash; namely, LLMs &amp;ndash; computer vision, and even standard statistical ML.&lt;/p>
&lt;h2 id="large-language-models-llms">
 Large Language Models (LLMs)
 &lt;a class="anchor" href="#large-language-models-llms">#&lt;/a>
&lt;/h2>
&lt;p>For initial iteration, using LLM APIs is probably the best way to go. There are several models out there, each with their own strengths. Below is an example using the &lt;a href="https://platform.openai.com/docs/quickstart?language-preference=python">OpenAI API&lt;/a> to make a call to a language model:&lt;/p></description></item><item><title>Using LLMs</title><link>http://localhost:1313/docs/ml/using-llms/</link><pubDate>Wed, 08 Jan 2025 10:55:07 -0800</pubDate><guid>http://localhost:1313/docs/ml/using-llms/</guid><description>&lt;h1 id="using-llms">
 Using LLMs
 &lt;a class="anchor" href="#using-llms">#&lt;/a>
&lt;/h1>
&lt;p>Below are some ways to go beyond just LLMs and use your custom data. These include methods such as Retrieval Augmented Generation (RAG), finetuning, and even searching over tabular data.&lt;/p>
&lt;h2 id="prompt-engineering">
 Prompt Engineering
 &lt;a class="anchor" href="#prompt-engineering">#&lt;/a>
&lt;/h2>
&lt;p>LLMs are trained on a ton of text, so we can often get a lot out of them just by clever prompting. Finding the best way to prompt a model is also known as &lt;a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/">&lt;strong>prompt engineering&lt;/strong>&lt;/a>, and there are several popular methods, including chain-of-thought (including the model&amp;rsquo;s reasoning step-by-step) as well as few-shot prompting (providing a few sample examples).&lt;/p></description></item><item><title>A Potpourri of Resources</title><link>http://localhost:1313/docs/ml/potpourri-resources/</link><pubDate>Wed, 08 Jan 2025 10:55:07 -0800</pubDate><guid>http://localhost:1313/docs/ml/potpourri-resources/</guid><description>&lt;h1 id="a-potpourri-of-resources">
 A Potpourri of Resources
 &lt;a class="anchor" href="#a-potpourri-of-resources">#&lt;/a>
&lt;/h1>
&lt;p>Below is a set of resources, ranging from popular AI/ML tooling to general advice.&lt;/p>
&lt;h2 id="general-advice">
 General Advice
 &lt;a class="anchor" href="#general-advice">#&lt;/a>
&lt;/h2>
&lt;p>Below are some general tips, aggregated from industry experts and 210 alums.&lt;/p>
&lt;h3 id="buy-first-then-build">
 Buy first, then Build
 &lt;a class="anchor" href="#buy-first-then-build">#&lt;/a>
&lt;/h3>
&lt;p>For initial functional prototyping and for most of the former part of your application&amp;rsquo;s lifecycle, lean on existing APIs to do a lot of the heavy lifting. These models are already quite powerful and are able to handle almost all of the requests you send it. If certain users or design partners necessitate even more advanced functionality, though, consider working and finetuning your own LLMs.&lt;/p></description></item></channel></rss>