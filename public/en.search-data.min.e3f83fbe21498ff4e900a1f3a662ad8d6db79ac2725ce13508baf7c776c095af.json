[{"id":0,"href":"/docs/ml/basic/","title":"Basic ML","section":"ML Engineering","content":" Basic ML # Below are some snippets for common ML use cases such as NLP \u0026ndash; namely, LLMs \u0026ndash; computer vision, and even standard statistical ML.\nLarge Language Models (LLMs) # For initial iteration, using LLM APIs is probably the best way to go. There are several models out there, each with their own strengths. Below is an example using the OpenAI API to make a call to a language model:\nfrom openai import OpenAI client = OpenAI() completion = client.chat.completions.create( model=\u0026#34;gpt-4o-mini\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Write a haiku about recursion in programming.\u0026#34; } ] ) print(completion.choices[0].message) As you continue to iterate, you may want to leverage the power of open-source models. For this, Hugging Face \u0026ndash; in particular, the SentenceTransformers module \u0026ndash; will be your best friend. Just specify your language model and you\u0026rsquo;ll be good to go:\nfrom sentence_transformers import SentenceTransformer model = SentenceTransformer(\u0026#39;paraphrase-MiniLM-L6-v2\u0026#39;) # Sentences we want to encode. Example: sentence = [\u0026#39;This framework generates embeddings for each input sentence\u0026#39;] # Sentences are encoded by calling model.encode() embedding = model.encode(sentence) Of course, utilizing an open-source model will also mean figuring out how to serve the model. There are a plethora of tools for this, including Modal, Baseten, Together AI, and many others.\nComputer Vision # Similar to LLMs, there are several Vision APIs available that can be used for quick experimentation. All of the larger cloud platforms have existing offerings \u0026ndash; namely GCP and Azure \u0026ndash; but it\u0026rsquo;s also important to note that many of the SOTA models are already multimodal. For instance, GPT-4V already has strong vision capabilities:\nfrom openai import OpenAI client = OpenAI() response = client.chat.completions.create( model=\u0026#34;gpt-4o-mini\u0026#34;, messages=[ { \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;What\u0026#39;s in this image?\u0026#34;}, { \u0026#34;type\u0026#34;: \u0026#34;image_url\u0026#34;, \u0026#34;image_url\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\u0026#34;, }, }, ], } ], max_tokens=300, ) print(response.choices[0]) For using custom models, torchvision \u0026ndash; and PyTorch more broadly \u0026ndash; are quite helpful. These packages allow us to both build our own models from scratch as well as use existing large pre-trained models. we can both An often common use case is to take a pre-trained image classification or segmentation model and further finetuning it for a specific task. This is also known as transfer learning, and there are several tutorials out there for the task.\nStatistical ML # Finally, for simple problems, statistical techniques may be sufficient. sklearn is often what\u0026rsquo;s used in industry for these tasks, and it can support tasks ranging from nearest neighbors clustering to gradient boosting. Here\u0026rsquo;s an example of using sklearn for linear regression:\nfrom sklearn.linear_model import LinearRegression import numpy as np # Create some sample data X = np.array([[1], [2], [3], [4], [5]]) # Features y = np.array([2, 4, 5, 4, 5]) # Target values # Create and fit the model model = LinearRegression() model.fit(X, y) # Make predictions predictions = model.predict(X) # Get model coefficients and intercept print(f\u0026#34;Slope: {model.coef_[0]:.2f}\u0026#34;) print(f\u0026#34;Intercept: {model.intercept_:.2f}\u0026#34;) # Calculate R-squared score r_squared = model.score(X, y) print(f\u0026#34;R-squared: {r_squared:.2f}\u0026#34;) "},{"id":1,"href":"/docs/class-resources/","title":"Class Resources","section":"Docs","content":" Class Resources # Below are some general class resources, ranging from deployment credits to general tools of the trade.\nVercel Credits # Students can create a Vercel Hobby account as soon as the class starts - Hobby accounts are always free If they\u0026rsquo;d like to explore Pro features, we\u0026rsquo;ve set up \u0026ldquo;Stanford CS\u0026rdquo; as a category in the Vercel Credits for Startups application page. Each team will receive $1,200 in credits. For \u0026ldquo;Proof of Partnership\u0026rdquo;, they should upload a screenshot of the syllabus / an e-mail from Jay about the course. A 14-day Pro Trial begins (they can email josh.oynick@vercel.com with any issues). At the end of the trial, if the teams choose to remain on Pro and add credit card info, the credits will begin to draw down. If teams add payment info, they are strongly encouraged to set hard spending limits right away (documentation). Tools of the Trade # Documentation # Github Wiki Here are some examples Project Management # Github issues, milestones, labels, comments Here is an example Real-time Team Communication # Slack, Messenger Discovery, Concepting Phase # Hand draw, Miro, Figma, GSlides Build Phase # Github Code (Pull request methodology) Github issues (code focused) Leverage Copilot, chatGPT, Bard as is useful GitHub Resources # Make sure your git activity is attributed to you Github Cheat Sheet - Page 1 Github Cheat Sheet - Page 2 How to make a Github pull request Miscellany Resources # Messaging Activation Matrix Beginner\u0026rsquo;s resources for Building Web and mobile apps CS210 Recommended Reads for Aspiring Program Managers/Product Leaders Contract of Deliverables Template Product Requirements Document (PRD) An incomplete list of ethics questions to consider Team Budget Guidelines Grading Rubric Make an animated gif from screen shots Digital sticky note option "},{"id":2,"href":"/docs/ml/extending-llms/","title":"Extending LLMs","section":"ML Engineering","content":" Extending LLMs # Below are some ways to go beyond just LLMs and use your custom data. These include methods such as finetuning, RAG, and even searching over tabular data.\nFinetuning # RAG # Tabular Data # "},{"id":3,"href":"/docs/ml/general-advice/","title":"General Advice","section":"ML Engineering","content":" General Advice # Below are some general tips, aggregated from industry experts and 210 alums.\nBuy first, not Build. # For initial functional prototyping and for most of the former part of your application\u0026rsquo;s lifecycle, lean on existing APIs to do a lot of the heavy lifting. These models are already quite powerful and are able to handle almost all of the requests you send it. If certain users or design partners necessitate even more advanced functionality, though, consider working and finetuning your own LLMs.\nWhen unsure, lean on the literature. # Oftentimes, issues with performance lie in the technical reports.\n"}]